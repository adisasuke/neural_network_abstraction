{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8da9f33d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\miniconda3\\envs\\ml\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\Admin\\miniconda3\\envs\\ml\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\Admin\\miniconda3\\envs\\ml\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\Admin\\miniconda3\\envs\\ml\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\Admin\\miniconda3\\envs\\ml\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\Admin\\miniconda3\\envs\\ml\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "C:\\Users\\Admin\\miniconda3\\envs\\ml\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\Admin\\miniconda3\\envs\\ml\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\Admin\\miniconda3\\envs\\ml\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\Admin\\miniconda3\\envs\\ml\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\Admin\\miniconda3\\envs\\ml\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\Admin\\miniconda3\\envs\\ml\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "from tensorflow import keras\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow import keras\n",
    "import pandas as pd\n",   
    "from matplotlib import pyplot as plt\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e6ee934c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"C:/Users/Admin/Desktop/Machine Learning/data/Bank customer/archive/Churn_Modelling.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "14f04a81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RowNumber</th>\n",
       "      <th>CustomerId</th>\n",
       "      <th>Surname</th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Geography</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>560</th>\n",
       "      <td>561</td>\n",
       "      <td>15670080</td>\n",
       "      <td>Mackenzie</td>\n",
       "      <td>584</td>\n",
       "      <td>Germany</td>\n",
       "      <td>Female</td>\n",
       "      <td>29</td>\n",
       "      <td>7</td>\n",
       "      <td>105204.01</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>138490.03</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9296</th>\n",
       "      <td>9297</td>\n",
       "      <td>15702442</td>\n",
       "      <td>Benson</td>\n",
       "      <td>586</td>\n",
       "      <td>Germany</td>\n",
       "      <td>Female</td>\n",
       "      <td>56</td>\n",
       "      <td>9</td>\n",
       "      <td>100781.75</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>54448.41</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1541</th>\n",
       "      <td>1542</td>\n",
       "      <td>15812497</td>\n",
       "      <td>D'Albertis</td>\n",
       "      <td>654</td>\n",
       "      <td>Germany</td>\n",
       "      <td>Male</td>\n",
       "      <td>37</td>\n",
       "      <td>5</td>\n",
       "      <td>112146.12</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>75927.35</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6696</th>\n",
       "      <td>6697</td>\n",
       "      <td>15587299</td>\n",
       "      <td>Board</td>\n",
       "      <td>567</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>48</td>\n",
       "      <td>3</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>55362.45</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4746</th>\n",
       "      <td>4747</td>\n",
       "      <td>15649129</td>\n",
       "      <td>Sal</td>\n",
       "      <td>757</td>\n",
       "      <td>France</td>\n",
       "      <td>Male</td>\n",
       "      <td>32</td>\n",
       "      <td>9</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>115950.96</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      RowNumber  CustomerId     Surname  CreditScore Geography  Gender  Age  \\\n",
       "560         561    15670080   Mackenzie          584   Germany  Female   29   \n",
       "9296       9297    15702442      Benson          586   Germany  Female   56   \n",
       "1541       1542    15812497  D'Albertis          654   Germany    Male   37   \n",
       "6696       6697    15587299       Board          567    France  Female   48   \n",
       "4746       4747    15649129         Sal          757    France    Male   32   \n",
       "\n",
       "      Tenure    Balance  NumOfProducts  HasCrCard  IsActiveMember  \\\n",
       "560        7  105204.01              1          0               1   \n",
       "9296       9  100781.75              2          1               1   \n",
       "1541       5  112146.12              1          1               0   \n",
       "6696       3       0.00              1          1               0   \n",
       "4746       9       0.00              2          1               0   \n",
       "\n",
       "      EstimatedSalary  Exited  \n",
       "560         138490.03       0  \n",
       "9296         54448.41       0  \n",
       "1541         75927.35       0  \n",
       "6696         55362.45       0  \n",
       "4746        115950.96       0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a8d78de4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    7963\n",
       "1    2037\n",
       "Name: Exited, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Exited'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "51e39f6f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df1 = df.drop(['RowNumber','CustomerId','Surname'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8093f0ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Geography</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6987</th>\n",
       "      <td>532</td>\n",
       "      <td>France</td>\n",
       "      <td>Male</td>\n",
       "      <td>60</td>\n",
       "      <td>5</td>\n",
       "      <td>76705.87</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>13889.73</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7162</th>\n",
       "      <td>607</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Male</td>\n",
       "      <td>34</td>\n",
       "      <td>9</td>\n",
       "      <td>132439.99</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>177747.72</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2134</th>\n",
       "      <td>713</td>\n",
       "      <td>France</td>\n",
       "      <td>Male</td>\n",
       "      <td>44</td>\n",
       "      <td>1</td>\n",
       "      <td>63438.91</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>64375.40</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6950</th>\n",
       "      <td>652</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>38</td>\n",
       "      <td>6</td>\n",
       "      <td>123081.84</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>188657.97</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2396</th>\n",
       "      <td>600</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>27</td>\n",
       "      <td>3</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>125698.97</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      CreditScore Geography  Gender  Age  Tenure    Balance  NumOfProducts  \\\n",
       "6987          532    France    Male   60       5   76705.87              2   \n",
       "7162          607     Spain    Male   34       9  132439.99              1   \n",
       "2134          713    France    Male   44       1   63438.91              1   \n",
       "6950          652     Spain  Female   38       6  123081.84              2   \n",
       "2396          600    France  Female   27       3       0.00              2   \n",
       "\n",
       "      HasCrCard  IsActiveMember  EstimatedSalary  Exited  \n",
       "6987          0               1         13889.73       0  \n",
       "7162          1               0        177747.72       0  \n",
       "2134          1               0         64375.40       0  \n",
       "6950          1               1        188657.97       0  \n",
       "2396          0               1        125698.97       0  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "407cbcde",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1['Gender'].replace({'Female':1,'Male':0},inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3cac3d72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Geography</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8094</th>\n",
       "      <td>614</td>\n",
       "      <td>Spain</td>\n",
       "      <td>0</td>\n",
       "      <td>66</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>180082.70</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5189</th>\n",
       "      <td>826</td>\n",
       "      <td>Spain</td>\n",
       "      <td>0</td>\n",
       "      <td>41</td>\n",
       "      <td>5</td>\n",
       "      <td>146466.46</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>180934.67</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2867</th>\n",
       "      <td>559</td>\n",
       "      <td>Spain</td>\n",
       "      <td>1</td>\n",
       "      <td>27</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1050.33</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9515</th>\n",
       "      <td>639</td>\n",
       "      <td>Spain</td>\n",
       "      <td>0</td>\n",
       "      <td>38</td>\n",
       "      <td>9</td>\n",
       "      <td>130233.14</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>81861.10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5410</th>\n",
       "      <td>623</td>\n",
       "      <td>France</td>\n",
       "      <td>1</td>\n",
       "      <td>28</td>\n",
       "      <td>4</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>41227.67</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      CreditScore Geography  Gender  Age  Tenure    Balance  NumOfProducts  \\\n",
       "8094          614     Spain       0   66       2       0.00              2   \n",
       "5189          826     Spain       0   41       5  146466.46              2   \n",
       "2867          559     Spain       1   27       1       0.00              1   \n",
       "9515          639     Spain       0   38       9  130233.14              1   \n",
       "5410          623    France       1   28       4       0.00              2   \n",
       "\n",
       "      HasCrCard  IsActiveMember  EstimatedSalary  Exited  \n",
       "8094          0               1        180082.70       0  \n",
       "5189          0               0        180934.67       0  \n",
       "2867          0               1          1050.33       0  \n",
       "9515          1               1         81861.10       0  \n",
       "5410          1               0         41227.67       0  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5cb5de66",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = pd.get_dummies(df1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a89b4b76",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "      <th>Geography_France</th>\n",
       "      <th>Geography_Germany</th>\n",
       "      <th>Geography_Spain</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4787</th>\n",
       "      <td>529</td>\n",
       "      <td>0</td>\n",
       "      <td>42</td>\n",
       "      <td>1</td>\n",
       "      <td>157498.90</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>82276.62</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5594</th>\n",
       "      <td>688</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>6</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>47886.44</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>950</th>\n",
       "      <td>635</td>\n",
       "      <td>1</td>\n",
       "      <td>48</td>\n",
       "      <td>8</td>\n",
       "      <td>130796.33</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>43250.30</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2409</th>\n",
       "      <td>654</td>\n",
       "      <td>0</td>\n",
       "      <td>37</td>\n",
       "      <td>2</td>\n",
       "      <td>145610.07</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>186300.59</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5529</th>\n",
       "      <td>691</td>\n",
       "      <td>0</td>\n",
       "      <td>34</td>\n",
       "      <td>8</td>\n",
       "      <td>133936.04</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>91359.79</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      CreditScore  Gender  Age  Tenure    Balance  NumOfProducts  HasCrCard  \\\n",
       "4787          529       0   42       1  157498.90              1          1   \n",
       "5594          688       0   40       6       0.00              1          1   \n",
       "950           635       1   48       8  130796.33              2          1   \n",
       "2409          654       0   37       2  145610.07              2          0   \n",
       "5529          691       0   34       8  133936.04              2          1   \n",
       "\n",
       "      IsActiveMember  EstimatedSalary  Exited  Geography_France  \\\n",
       "4787               1         82276.62       0                 1   \n",
       "5594               1         47886.44       0                 1   \n",
       "950                1         43250.30       0                 1   \n",
       "2409               0        186300.59       0                 0   \n",
       "5529               0         91359.79       0                 1   \n",
       "\n",
       "      Geography_Germany  Geography_Spain  \n",
       "4787                  0                0  \n",
       "5594                  0                0  \n",
       "950                   0                0  \n",
       "2409                  1                0  \n",
       "5529                  0                0  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9834ee99",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "df2[:] = scaler.fit_transform(df2[:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3dd034b0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "      <th>Geography_France</th>\n",
       "      <th>Geography_Germany</th>\n",
       "      <th>Geography_Spain</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9975</th>\n",
       "      <td>0.520</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.432432</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.454196</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.982669</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6485</th>\n",
       "      <td>0.580</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.108108</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.360317</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.016437</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2063</th>\n",
       "      <td>0.476</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.229730</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.410767</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.899358</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1554</th>\n",
       "      <td>0.556</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.216216</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.632693</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.630965</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>859</th>\n",
       "      <td>0.496</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.621622</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.978212</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      CreditScore  Gender       Age  Tenure   Balance  NumOfProducts  \\\n",
       "9975        0.520     0.0  0.432432     0.1  0.454196       0.333333   \n",
       "6485        0.580     0.0  0.108108     0.5  0.360317       0.000000   \n",
       "2063        0.476     1.0  0.229730     0.1  0.410767       0.000000   \n",
       "1554        0.556     0.0  0.216216     0.4  0.632693       0.333333   \n",
       "859         0.496     0.0  0.621622     0.1  0.000000       0.333333   \n",
       "\n",
       "      HasCrCard  IsActiveMember  EstimatedSalary  Exited  Geography_France  \\\n",
       "9975        1.0             0.0         0.982669     1.0               0.0   \n",
       "6485        1.0             1.0         0.016437     0.0               0.0   \n",
       "2063        1.0             0.0         0.899358     1.0               0.0   \n",
       "1554        1.0             1.0         0.630965     0.0               1.0   \n",
       "859         1.0             0.0         0.978212     1.0               1.0   \n",
       "\n",
       "      Geography_Germany  Geography_Spain  \n",
       "9975                1.0              0.0  \n",
       "6485                1.0              0.0  \n",
       "2063                1.0              0.0  \n",
       "1554                0.0              0.0  \n",
       "859                 0.0              0.0  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "34ad30c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df2.drop('Exited',axis=1)\n",
    "y = df2['Exited']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "159599c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 12)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a041570e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ANN(x_train,y_train,x_test,y_test):\n",
    "    model = keras.Sequential([\n",
    "        keras.layers.Dense(100,input_shape=(12,),activation='relu'),\n",
    "        keras.layers.Dropout(0.5),\n",
    "        keras.layers.Dense(10,activation='relu'),\n",
    "        keras.layers.Dropout(0.5),\n",
    "        keras.layers.Dense(1,activation='sigmoid')\n",
    "    ])\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    model.fit(x_train,y_train,epochs=100)\n",
    "    model.evaluate(x_test,y_test)\n",
    "    y_predicted = model.predict(x_test)\n",
    "    y_pred = []\n",
    "    for i in y_predicted:\n",
    "        if(i>0.5):\n",
    "            y_pred.append(1)\n",
    "        else:\n",
    "            y_pred.append(0)\n",
    "        \n",
    "        \n",
    "    print(classification_report(y_test,y_pred))\n",
    "    return y_pred\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "44dfd5b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#undersample data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "773c9981",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0    7963\n",
       "1.0    2037\n",
       "Name: Exited, dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4940ad43",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_undersample_class0 = df2[df2['Exited']==0]\n",
    "df_undersample_class1 = df2[df2['Exited']==1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0950cfd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_undersample_class0  = df_undersample_class0.sample(2037)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5745b405",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_undersample = pd.concat([df_undersample_class0,df_undersample_class1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2ed724da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0    2037\n",
       "1.0    2037\n",
       "Name: Exited, dtype: int64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_undersample['Exited'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0d6f157a",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_undersample = df_undersample.drop('Exited',axis=1)\n",
    "y_undersample = df_undersample['Exited']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2cd759ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train,x_test,y_train,y_test = train_test_split(x_undersample,y_undersample,test_size=0.33,random_state=45,stratify=y_undersample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "043daf83",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1345,)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d3247f3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Admin\\miniconda3\\envs\\ml\\lib\\site-packages\\tensorflow\\python\\ops\\init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From C:\\Users\\Admin\\miniconda3\\envs\\ml\\lib\\site-packages\\tensorflow\\python\\ops\\nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "Epoch 1/100\n",
      "2729/2729 [==============================] - 0s 47us/sample - loss: 0.6970 - acc: 0.5280\n",
      "Epoch 2/100\n",
      "2729/2729 [==============================] - 0s 22us/sample - loss: 0.6745 - acc: 0.5892\n",
      "Epoch 3/100\n",
      "2729/2729 [==============================] - 0s 24us/sample - loss: 0.6619 - acc: 0.5973\n",
      "Epoch 4/100\n",
      "2729/2729 [==============================] - 0s 18us/sample - loss: 0.6534 - acc: 0.6240\n",
      "Epoch 5/100\n",
      "2729/2729 [==============================] - 0s 15us/sample - loss: 0.6473 - acc: 0.6251\n",
      "Epoch 6/100\n",
      "2729/2729 [==============================] - 0s 24us/sample - loss: 0.6370 - acc: 0.6343\n",
      "Epoch 7/100\n",
      "2729/2729 [==============================] - 0s 17us/sample - loss: 0.6354 - acc: 0.6468\n",
      "Epoch 8/100\n",
      "2729/2729 [==============================] - 0s 26us/sample - loss: 0.6285 - acc: 0.6581\n",
      "Epoch 9/100\n",
      "2729/2729 [==============================] - 0s 22us/sample - loss: 0.6275 - acc: 0.6618\n",
      "Epoch 10/100\n",
      "2729/2729 [==============================] - 0s 21us/sample - loss: 0.6149 - acc: 0.6720\n",
      "Epoch 11/100\n",
      "2729/2729 [==============================] - 0s 17us/sample - loss: 0.6081 - acc: 0.6786\n",
      "Epoch 12/100\n",
      "2729/2729 [==============================] - 0s 20us/sample - loss: 0.6159 - acc: 0.6665\n",
      "Epoch 13/100\n",
      "2729/2729 [==============================] - 0s 21us/sample - loss: 0.6056 - acc: 0.6801\n",
      "Epoch 14/100\n",
      "2729/2729 [==============================] - 0s 19us/sample - loss: 0.5958 - acc: 0.6915\n",
      "Epoch 15/100\n",
      "2729/2729 [==============================] - 0s 20us/sample - loss: 0.5964 - acc: 0.6900\n",
      "Epoch 16/100\n",
      "2729/2729 [==============================] - 0s 22us/sample - loss: 0.5947 - acc: 0.6981\n",
      "Epoch 17/100\n",
      "2729/2729 [==============================] - 0s 20us/sample - loss: 0.5921 - acc: 0.7091\n",
      "Epoch 18/100\n",
      "2729/2729 [==============================] - 0s 18us/sample - loss: 0.5897 - acc: 0.6951\n",
      "Epoch 19/100\n",
      "2729/2729 [==============================] - 0s 20us/sample - loss: 0.5775 - acc: 0.7164\n",
      "Epoch 20/100\n",
      "2729/2729 [==============================] - 0s 17us/sample - loss: 0.5822 - acc: 0.7017\n",
      "Epoch 21/100\n",
      "2729/2729 [==============================] - 0s 18us/sample - loss: 0.5626 - acc: 0.7175\n",
      "Epoch 22/100\n",
      "2729/2729 [==============================] - 0s 21us/sample - loss: 0.5715 - acc: 0.7112\n",
      "Epoch 23/100\n",
      "2729/2729 [==============================] - 0s 17us/sample - loss: 0.5605 - acc: 0.7244\n",
      "Epoch 24/100\n",
      "2729/2729 [==============================] - 0s 23us/sample - loss: 0.5564 - acc: 0.7222\n",
      "Epoch 25/100\n",
      "2729/2729 [==============================] - 0s 18us/sample - loss: 0.5565 - acc: 0.7314\n",
      "Epoch 26/100\n",
      "2729/2729 [==============================] - 0s 18us/sample - loss: 0.5530 - acc: 0.7204\n",
      "Epoch 27/100\n",
      "2729/2729 [==============================] - 0s 18us/sample - loss: 0.5532 - acc: 0.7369\n",
      "Epoch 28/100\n",
      "2729/2729 [==============================] - 0s 17us/sample - loss: 0.5432 - acc: 0.7387\n",
      "Epoch 29/100\n",
      "2729/2729 [==============================] - 0s 17us/sample - loss: 0.5461 - acc: 0.7343\n",
      "Epoch 30/100\n",
      "2729/2729 [==============================] - 0s 18us/sample - loss: 0.5362 - acc: 0.7413\n",
      "Epoch 31/100\n",
      "2729/2729 [==============================] - 0s 21us/sample - loss: 0.5325 - acc: 0.7398\n",
      "Epoch 32/100\n",
      "2729/2729 [==============================] - 0s 22us/sample - loss: 0.5345 - acc: 0.7417\n",
      "Epoch 33/100\n",
      "2729/2729 [==============================] - 0s 18us/sample - loss: 0.5400 - acc: 0.7354\n",
      "Epoch 34/100\n",
      "2729/2729 [==============================] - 0s 18us/sample - loss: 0.5376 - acc: 0.7354\n",
      "Epoch 35/100\n",
      "2729/2729 [==============================] - 0s 18us/sample - loss: 0.5249 - acc: 0.7475\n",
      "Epoch 36/100\n",
      "2729/2729 [==============================] - 0s 18us/sample - loss: 0.5292 - acc: 0.7571\n",
      "Epoch 37/100\n",
      "2729/2729 [==============================] - 0s 18us/sample - loss: 0.5241 - acc: 0.7479\n",
      "Epoch 38/100\n",
      "2729/2729 [==============================] - 0s 18us/sample - loss: 0.5245 - acc: 0.7483\n",
      "Epoch 39/100\n",
      "2729/2729 [==============================] - 0s 17us/sample - loss: 0.5145 - acc: 0.7593\n",
      "Epoch 40/100\n",
      "2729/2729 [==============================] - 0s 18us/sample - loss: 0.5141 - acc: 0.7402\n",
      "Epoch 41/100\n",
      "2729/2729 [==============================] - 0s 18us/sample - loss: 0.5177 - acc: 0.7494\n",
      "Epoch 42/100\n",
      "2729/2729 [==============================] - 0s 18us/sample - loss: 0.5108 - acc: 0.7567\n",
      "Epoch 43/100\n",
      "2729/2729 [==============================] - 0s 18us/sample - loss: 0.5172 - acc: 0.7538\n",
      "Epoch 44/100\n",
      "2729/2729 [==============================] - 0s 17us/sample - loss: 0.5137 - acc: 0.7530\n",
      "Epoch 45/100\n",
      "2729/2729 [==============================] - 0s 19us/sample - loss: 0.5078 - acc: 0.7512\n",
      "Epoch 46/100\n",
      "2729/2729 [==============================] - 0s 18us/sample - loss: 0.5137 - acc: 0.7552\n",
      "Epoch 47/100\n",
      "2729/2729 [==============================] - 0s 18us/sample - loss: 0.5103 - acc: 0.7578\n",
      "Epoch 48/100\n",
      "2729/2729 [==============================] - 0s 18us/sample - loss: 0.5109 - acc: 0.7574\n",
      "Epoch 49/100\n",
      "2729/2729 [==============================] - 0s 18us/sample - loss: 0.5039 - acc: 0.7636\n",
      "Epoch 50/100\n",
      "2729/2729 [==============================] - 0s 18us/sample - loss: 0.5117 - acc: 0.7516\n",
      "Epoch 51/100\n",
      "2729/2729 [==============================] - 0s 18us/sample - loss: 0.5084 - acc: 0.7574\n",
      "Epoch 52/100\n",
      "2729/2729 [==============================] - 0s 18us/sample - loss: 0.5070 - acc: 0.7578\n",
      "Epoch 53/100\n",
      "2729/2729 [==============================] - 0s 18us/sample - loss: 0.5036 - acc: 0.7571\n",
      "Epoch 54/100\n",
      "2729/2729 [==============================] - 0s 23us/sample - loss: 0.5082 - acc: 0.7596\n",
      "Epoch 55/100\n",
      "2729/2729 [==============================] - 0s 18us/sample - loss: 0.4978 - acc: 0.7556\n",
      "Epoch 56/100\n",
      "2729/2729 [==============================] - 0s 17us/sample - loss: 0.5055 - acc: 0.7538\n",
      "Epoch 57/100\n",
      "2729/2729 [==============================] - 0s 17us/sample - loss: 0.5077 - acc: 0.7556\n",
      "Epoch 58/100\n",
      "2729/2729 [==============================] - 0s 14us/sample - loss: 0.5135 - acc: 0.7541\n",
      "Epoch 59/100\n",
      "2729/2729 [==============================] - 0s 23us/sample - loss: 0.5037 - acc: 0.7585\n",
      "Epoch 60/100\n",
      "2729/2729 [==============================] - 0s 20us/sample - loss: 0.4964 - acc: 0.7644\n",
      "Epoch 61/100\n",
      "2729/2729 [==============================] - 0s 17us/sample - loss: 0.5004 - acc: 0.7545\n",
      "Epoch 62/100\n",
      "2729/2729 [==============================] - 0s 20us/sample - loss: 0.5021 - acc: 0.7567\n",
      "Epoch 63/100\n",
      "2729/2729 [==============================] - 0s 16us/sample - loss: 0.4844 - acc: 0.7636\n",
      "Epoch 64/100\n",
      "2729/2729 [==============================] - 0s 20us/sample - loss: 0.5105 - acc: 0.7497\n",
      "Epoch 65/100\n",
      "2729/2729 [==============================] - 0s 16us/sample - loss: 0.4987 - acc: 0.7560\n",
      "Epoch 66/100\n",
      "2729/2729 [==============================] - 0s 20us/sample - loss: 0.4973 - acc: 0.7647\n",
      "Epoch 67/100\n",
      "2729/2729 [==============================] - 0s 17us/sample - loss: 0.4912 - acc: 0.7680\n",
      "Epoch 68/100\n",
      "2729/2729 [==============================] - 0s 21us/sample - loss: 0.4997 - acc: 0.7563\n",
      "Epoch 69/100\n",
      "2729/2729 [==============================] - 0s 17us/sample - loss: 0.4910 - acc: 0.7486\n",
      "Epoch 70/100\n",
      "2729/2729 [==============================] - 0s 20us/sample - loss: 0.4966 - acc: 0.7688\n",
      "Epoch 71/100\n",
      "2729/2729 [==============================] - 0s 18us/sample - loss: 0.4933 - acc: 0.7644\n",
      "Epoch 72/100\n",
      "2729/2729 [==============================] - 0s 15us/sample - loss: 0.4926 - acc: 0.7651\n",
      "Epoch 73/100\n",
      "2729/2729 [==============================] - 0s 23us/sample - loss: 0.4960 - acc: 0.7677\n",
      "Epoch 74/100\n",
      "2729/2729 [==============================] - 0s 19us/sample - loss: 0.4937 - acc: 0.7633\n",
      "Epoch 75/100\n",
      "2729/2729 [==============================] - 0s 18us/sample - loss: 0.4921 - acc: 0.7688\n",
      "Epoch 76/100\n",
      "2729/2729 [==============================] - 0s 20us/sample - loss: 0.4851 - acc: 0.7680\n",
      "Epoch 77/100\n",
      "2729/2729 [==============================] - 0s 17us/sample - loss: 0.4973 - acc: 0.7626\n",
      "Epoch 78/100\n",
      "2729/2729 [==============================] - 0s 17us/sample - loss: 0.4921 - acc: 0.7691\n",
      "Epoch 79/100\n",
      "2729/2729 [==============================] - 0s 18us/sample - loss: 0.4893 - acc: 0.7640\n",
      "Epoch 80/100\n",
      "2729/2729 [==============================] - 0s 18us/sample - loss: 0.4907 - acc: 0.7600\n",
      "Epoch 81/100\n",
      "2729/2729 [==============================] - 0s 18us/sample - loss: 0.4916 - acc: 0.7633\n",
      "Epoch 82/100\n",
      "2729/2729 [==============================] - 0s 18us/sample - loss: 0.4839 - acc: 0.7669\n",
      "Epoch 83/100\n",
      "2729/2729 [==============================] - 0s 18us/sample - loss: 0.4976 - acc: 0.7618\n",
      "Epoch 84/100\n",
      "2729/2729 [==============================] - 0s 18us/sample - loss: 0.4956 - acc: 0.7596\n",
      "Epoch 85/100\n",
      "2729/2729 [==============================] - 0s 18us/sample - loss: 0.4858 - acc: 0.7717\n",
      "Epoch 86/100\n",
      "2729/2729 [==============================] - 0s 18us/sample - loss: 0.4931 - acc: 0.7618\n",
      "Epoch 87/100\n",
      "2729/2729 [==============================] - 0s 20us/sample - loss: 0.4898 - acc: 0.7633\n",
      "Epoch 88/100\n",
      "2729/2729 [==============================] - 0s 20us/sample - loss: 0.4856 - acc: 0.7721\n",
      "Epoch 89/100\n",
      "2729/2729 [==============================] - 0s 19us/sample - loss: 0.4885 - acc: 0.7666\n",
      "Epoch 90/100\n",
      "2729/2729 [==============================] - 0s 18us/sample - loss: 0.4840 - acc: 0.7633\n",
      "Epoch 91/100\n",
      "2729/2729 [==============================] - 0s 19us/sample - loss: 0.4797 - acc: 0.7593\n",
      "Epoch 92/100\n",
      "2729/2729 [==============================] - 0s 18us/sample - loss: 0.4962 - acc: 0.7618\n",
      "Epoch 93/100\n",
      "2729/2729 [==============================] - 0s 18us/sample - loss: 0.4851 - acc: 0.7545\n",
      "Epoch 94/100\n",
      "2729/2729 [==============================] - 0s 18us/sample - loss: 0.4938 - acc: 0.7604\n",
      "Epoch 95/100\n",
      "2729/2729 [==============================] - 0s 17us/sample - loss: 0.4877 - acc: 0.7684\n",
      "Epoch 96/100\n",
      "2729/2729 [==============================] - 0s 18us/sample - loss: 0.4894 - acc: 0.7666\n",
      "Epoch 97/100\n",
      "2729/2729 [==============================] - 0s 18us/sample - loss: 0.4970 - acc: 0.7538\n",
      "Epoch 98/100\n",
      "2729/2729 [==============================] - 0s 16us/sample - loss: 0.4833 - acc: 0.7724\n",
      "Epoch 99/100\n",
      "2729/2729 [==============================] - 0s 20us/sample - loss: 0.4817 - acc: 0.7662\n",
      "Epoch 100/100\n",
      "2729/2729 [==============================] - 0s 18us/sample - loss: 0.4890 - acc: 0.7724\n",
      "1345/1345 [==============================] - 0s 21us/sample - loss: 0.4715 - acc: 0.7673\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.74      0.82      0.78       672\n",
      "         1.0       0.80      0.72      0.75       673\n",
      "\n",
      "    accuracy                           0.77      1345\n",
      "   macro avg       0.77      0.77      0.77      1345\n",
      "weighted avg       0.77      0.77      0.77      1345\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " ...]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ANN(x_train,y_train,x_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d6c0f450",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Oversample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d65bb6cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_oversample_class0 = df2[df2['Exited']==0]\n",
    "df_oversample_class1 = df2[df2['Exited']==1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c291c00c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7963, 13)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_oversample_class0.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "755ed44e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_oversample_class1 = df_oversample_class1.sample(7963,replace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5fac64d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_oversample = pd.concat([df_oversample_class0,df_oversample_class1],axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "621119ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0    7963\n",
       "1.0    7963\n",
       "Name: Exited, dtype: int64"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_oversample['Exited'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "48043a33",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_oversample = df_oversample.drop('Exited',axis=1)\n",
    "y_oversample = df_oversample['Exited']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e14a77b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train,x_test,y_train,y_test = train_test_split(x_oversample,y_oversample,test_size=0.33,random_state=45,stratify=y_oversample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7523a355",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "10670/10670 [==============================] - 0s 26us/sample - loss: 0.6724 - acc: 0.5801\n",
      "Epoch 2/100\n",
      "10670/10670 [==============================] - 0s 20us/sample - loss: 0.6373 - acc: 0.6425\n",
      "Epoch 3/100\n",
      "10670/10670 [==============================] - 0s 21us/sample - loss: 0.6191 - acc: 0.6645\n",
      "Epoch 4/100\n",
      "10670/10670 [==============================] - 0s 19us/sample - loss: 0.6049 - acc: 0.6729\n",
      "Epoch 5/100\n",
      "10670/10670 [==============================] - 0s 19us/sample - loss: 0.5849 - acc: 0.6975\n",
      "Epoch 6/100\n",
      "10670/10670 [==============================] - 0s 18us/sample - loss: 0.5619 - acc: 0.7221\n",
      "Epoch 7/100\n",
      "10670/10670 [==============================] - 0s 18us/sample - loss: 0.5507 - acc: 0.7292\n",
      "Epoch 8/100\n",
      "10670/10670 [==============================] - 0s 19us/sample - loss: 0.5356 - acc: 0.7428\n",
      "Epoch 9/100\n",
      "10670/10670 [==============================] - 0s 20us/sample - loss: 0.5281 - acc: 0.7393\n",
      "Epoch 10/100\n",
      "10670/10670 [==============================] - 0s 21us/sample - loss: 0.5298 - acc: 0.7421\n",
      "Epoch 11/100\n",
      "10670/10670 [==============================] - 0s 18us/sample - loss: 0.5172 - acc: 0.7486\n",
      "Epoch 12/100\n",
      "10670/10670 [==============================] - 0s 18us/sample - loss: 0.5109 - acc: 0.7492\n",
      "Epoch 13/100\n",
      "10670/10670 [==============================] - 0s 18us/sample - loss: 0.5094 - acc: 0.7527\n",
      "Epoch 14/100\n",
      "10670/10670 [==============================] - 0s 18us/sample - loss: 0.5115 - acc: 0.7511\n",
      "Epoch 15/100\n",
      "10670/10670 [==============================] - 0s 19us/sample - loss: 0.5031 - acc: 0.7557\n",
      "Epoch 16/100\n",
      "10670/10670 [==============================] - 0s 18us/sample - loss: 0.5006 - acc: 0.7566\n",
      "Epoch 17/100\n",
      "10670/10670 [==============================] - 0s 18us/sample - loss: 0.5033 - acc: 0.7554\n",
      "Epoch 18/100\n",
      "10670/10670 [==============================] - 0s 18us/sample - loss: 0.4997 - acc: 0.7554\n",
      "Epoch 19/100\n",
      "10670/10670 [==============================] - 0s 18us/sample - loss: 0.5019 - acc: 0.7524\n",
      "Epoch 20/100\n",
      "10670/10670 [==============================] - 0s 18us/sample - loss: 0.4971 - acc: 0.7591\n",
      "Epoch 21/100\n",
      "10670/10670 [==============================] - 0s 18us/sample - loss: 0.4946 - acc: 0.7578\n",
      "Epoch 22/100\n",
      "10670/10670 [==============================] - 0s 19us/sample - loss: 0.4938 - acc: 0.7553\n",
      "Epoch 23/100\n",
      "10670/10670 [==============================] - 0s 20us/sample - loss: 0.4899 - acc: 0.7604\n",
      "Epoch 24/100\n",
      "10670/10670 [==============================] - 0s 19us/sample - loss: 0.4893 - acc: 0.7622\n",
      "Epoch 25/100\n",
      "10670/10670 [==============================] - 0s 20us/sample - loss: 0.4889 - acc: 0.7613\n",
      "Epoch 26/100\n",
      "10670/10670 [==============================] - 0s 19us/sample - loss: 0.4891 - acc: 0.7601\n",
      "Epoch 27/100\n",
      "10670/10670 [==============================] - 0s 18us/sample - loss: 0.4883 - acc: 0.7627\n",
      "Epoch 28/100\n",
      "10670/10670 [==============================] - 0s 21us/sample - loss: 0.4922 - acc: 0.7592\n",
      "Epoch 29/100\n",
      "10670/10670 [==============================] - 0s 19us/sample - loss: 0.4904 - acc: 0.7619\n",
      "Epoch 30/100\n",
      "10670/10670 [==============================] - 0s 18us/sample - loss: 0.4919 - acc: 0.7618\n",
      "Epoch 31/100\n",
      "10670/10670 [==============================] - 0s 18us/sample - loss: 0.4825 - acc: 0.7694\n",
      "Epoch 32/100\n",
      "10670/10670 [==============================] - 0s 19us/sample - loss: 0.4827 - acc: 0.7616\n",
      "Epoch 33/100\n",
      "10670/10670 [==============================] - 0s 19us/sample - loss: 0.4848 - acc: 0.7642\n",
      "Epoch 34/100\n",
      "10670/10670 [==============================] - 0s 20us/sample - loss: 0.4853 - acc: 0.7642\n",
      "Epoch 35/100\n",
      "10670/10670 [==============================] - 0s 19us/sample - loss: 0.4789 - acc: 0.7644\n",
      "Epoch 36/100\n",
      "10670/10670 [==============================] - 0s 19us/sample - loss: 0.4798 - acc: 0.7620\n",
      "Epoch 37/100\n",
      "10670/10670 [==============================] - 0s 20us/sample - loss: 0.4858 - acc: 0.7647\n",
      "Epoch 38/100\n",
      "10670/10670 [==============================] - 0s 20us/sample - loss: 0.4816 - acc: 0.7627\n",
      "Epoch 39/100\n",
      "10670/10670 [==============================] - 0s 20us/sample - loss: 0.4807 - acc: 0.7656\n",
      "Epoch 40/100\n",
      "10670/10670 [==============================] - 0s 21us/sample - loss: 0.4806 - acc: 0.7678\n",
      "Epoch 41/100\n",
      "10670/10670 [==============================] - 0s 20us/sample - loss: 0.4786 - acc: 0.7651\n",
      "Epoch 42/100\n",
      "10670/10670 [==============================] - 0s 18us/sample - loss: 0.4804 - acc: 0.7682\n",
      "Epoch 43/100\n",
      "10670/10670 [==============================] - 0s 18us/sample - loss: 0.4785 - acc: 0.7665\n",
      "Epoch 44/100\n",
      "10670/10670 [==============================] - 0s 18us/sample - loss: 0.4826 - acc: 0.7657\n",
      "Epoch 45/100\n",
      "10670/10670 [==============================] - 0s 18us/sample - loss: 0.4790 - acc: 0.7643\n",
      "Epoch 46/100\n",
      "10670/10670 [==============================] - 0s 19us/sample - loss: 0.4766 - acc: 0.7709\n",
      "Epoch 47/100\n",
      "10670/10670 [==============================] - 0s 18us/sample - loss: 0.4764 - acc: 0.7687\n",
      "Epoch 48/100\n",
      "10670/10670 [==============================] - 0s 18us/sample - loss: 0.4743 - acc: 0.7641\n",
      "Epoch 49/100\n",
      "10670/10670 [==============================] - 0s 18us/sample - loss: 0.4776 - acc: 0.7686\n",
      "Epoch 50/100\n",
      "10670/10670 [==============================] - 0s 19us/sample - loss: 0.4731 - acc: 0.7709\n",
      "Epoch 51/100\n",
      "10670/10670 [==============================] - 0s 18us/sample - loss: 0.4767 - acc: 0.7674\n",
      "Epoch 52/100\n",
      "10670/10670 [==============================] - 0s 18us/sample - loss: 0.4767 - acc: 0.7697\n",
      "Epoch 53/100\n",
      "10670/10670 [==============================] - 0s 18us/sample - loss: 0.4772 - acc: 0.7668\n",
      "Epoch 54/100\n",
      "10670/10670 [==============================] - 0s 17us/sample - loss: 0.4733 - acc: 0.7697\n",
      "Epoch 55/100\n",
      "10670/10670 [==============================] - 0s 19us/sample - loss: 0.4727 - acc: 0.7700\n",
      "Epoch 56/100\n",
      "10670/10670 [==============================] - 0s 17us/sample - loss: 0.4772 - acc: 0.7696\n",
      "Epoch 57/100\n",
      "10670/10670 [==============================] - 0s 19us/sample - loss: 0.4732 - acc: 0.7701\n",
      "Epoch 58/100\n",
      "10670/10670 [==============================] - 0s 18us/sample - loss: 0.4790 - acc: 0.7684\n",
      "Epoch 59/100\n",
      "10670/10670 [==============================] - 0s 18us/sample - loss: 0.4687 - acc: 0.7739\n",
      "Epoch 60/100\n",
      "10670/10670 [==============================] - 0s 18us/sample - loss: 0.4674 - acc: 0.7742\n",
      "Epoch 61/100\n",
      "10670/10670 [==============================] - 0s 18us/sample - loss: 0.4666 - acc: 0.7724\n",
      "Epoch 62/100\n",
      "10670/10670 [==============================] - 0s 18us/sample - loss: 0.4677 - acc: 0.7711\n",
      "Epoch 63/100\n",
      "10670/10670 [==============================] - 0s 18us/sample - loss: 0.4731 - acc: 0.7656\n",
      "Epoch 64/100\n",
      "10670/10670 [==============================] - 0s 18us/sample - loss: 0.4720 - acc: 0.7711\n",
      "Epoch 65/100\n",
      "10670/10670 [==============================] - 0s 18us/sample - loss: 0.4714 - acc: 0.7668\n",
      "Epoch 66/100\n",
      "10670/10670 [==============================] - 0s 18us/sample - loss: 0.4628 - acc: 0.7721\n",
      "Epoch 67/100\n",
      "10670/10670 [==============================] - 0s 18us/sample - loss: 0.4693 - acc: 0.7713\n",
      "Epoch 68/100\n",
      "10670/10670 [==============================] - 0s 21us/sample - loss: 0.4688 - acc: 0.7744\n",
      "Epoch 69/100\n",
      "10670/10670 [==============================] - 0s 18us/sample - loss: 0.4694 - acc: 0.7712\n",
      "Epoch 70/100\n",
      "10670/10670 [==============================] - 0s 16us/sample - loss: 0.4780 - acc: 0.7667\n",
      "Epoch 71/100\n",
      "10670/10670 [==============================] - 0s 18us/sample - loss: 0.4681 - acc: 0.7725\n",
      "Epoch 72/100\n",
      "10670/10670 [==============================] - 0s 18us/sample - loss: 0.4677 - acc: 0.7727\n",
      "Epoch 73/100\n",
      "10670/10670 [==============================] - 0s 18us/sample - loss: 0.4714 - acc: 0.7695\n",
      "Epoch 74/100\n",
      "10670/10670 [==============================] - 0s 18us/sample - loss: 0.4730 - acc: 0.7712\n",
      "Epoch 75/100\n",
      "10670/10670 [==============================] - 0s 18us/sample - loss: 0.4701 - acc: 0.7712\n",
      "Epoch 76/100\n",
      "10670/10670 [==============================] - 0s 18us/sample - loss: 0.4705 - acc: 0.7704\n",
      "Epoch 77/100\n",
      "10670/10670 [==============================] - 0s 18us/sample - loss: 0.4704 - acc: 0.7729\n",
      "Epoch 78/100\n",
      "10670/10670 [==============================] - 0s 18us/sample - loss: 0.4701 - acc: 0.7733\n",
      "Epoch 79/100\n",
      "10670/10670 [==============================] - 0s 18us/sample - loss: 0.4700 - acc: 0.7703\n",
      "Epoch 80/100\n",
      "10670/10670 [==============================] - 0s 18us/sample - loss: 0.4669 - acc: 0.7750\n",
      "Epoch 81/100\n",
      "10670/10670 [==============================] - 0s 18us/sample - loss: 0.4721 - acc: 0.7719\n",
      "Epoch 82/100\n",
      "10670/10670 [==============================] - 0s 18us/sample - loss: 0.4638 - acc: 0.7728\n",
      "Epoch 83/100\n",
      "10670/10670 [==============================] - 0s 19us/sample - loss: 0.4691 - acc: 0.7733\n",
      "Epoch 84/100\n",
      "10670/10670 [==============================] - 0s 18us/sample - loss: 0.4636 - acc: 0.7784\n",
      "Epoch 85/100\n",
      "10670/10670 [==============================] - 0s 20us/sample - loss: 0.4723 - acc: 0.7733\n",
      "Epoch 86/100\n",
      "10670/10670 [==============================] - 0s 18us/sample - loss: 0.4673 - acc: 0.7734\n",
      "Epoch 87/100\n",
      "10670/10670 [==============================] - 0s 18us/sample - loss: 0.4654 - acc: 0.7718\n",
      "Epoch 88/100\n",
      "10670/10670 [==============================] - 0s 19us/sample - loss: 0.4647 - acc: 0.7723\n",
      "Epoch 89/100\n",
      "10670/10670 [==============================] - 0s 18us/sample - loss: 0.4710 - acc: 0.7716\n",
      "Epoch 90/100\n",
      "10670/10670 [==============================] - 0s 18us/sample - loss: 0.4672 - acc: 0.7706\n",
      "Epoch 91/100\n",
      "10670/10670 [==============================] - 0s 20us/sample - loss: 0.4614 - acc: 0.7741\n",
      "Epoch 92/100\n",
      "10670/10670 [==============================] - 0s 19us/sample - loss: 0.4611 - acc: 0.7764\n",
      "Epoch 93/100\n",
      "10670/10670 [==============================] - 0s 18us/sample - loss: 0.4634 - acc: 0.7749\n",
      "Epoch 94/100\n",
      "10670/10670 [==============================] - 0s 18us/sample - loss: 0.4633 - acc: 0.7748\n",
      "Epoch 95/100\n",
      "10670/10670 [==============================] - 0s 18us/sample - loss: 0.4628 - acc: 0.7763\n",
      "Epoch 96/100\n",
      "10670/10670 [==============================] - 0s 18us/sample - loss: 0.4686 - acc: 0.7742\n",
      "Epoch 97/100\n",
      "10670/10670 [==============================] - 0s 18us/sample - loss: 0.4671 - acc: 0.7733\n",
      "Epoch 98/100\n",
      "10670/10670 [==============================] - 0s 18us/sample - loss: 0.4722 - acc: 0.7682\n",
      "Epoch 99/100\n",
      "10670/10670 [==============================] - 0s 18us/sample - loss: 0.4605 - acc: 0.7812\n",
      "Epoch 100/100\n",
      "10670/10670 [==============================] - 0s 18us/sample - loss: 0.4647 - acc: 0.7720\n",
      "5256/5256 [==============================] - 0s 12us/sample - loss: 0.4423 - acc: 0.7801\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.76      0.82      0.79      2628\n",
      "         1.0       0.80      0.74      0.77      2628\n",
      "\n",
      "    accuracy                           0.78      5256\n",
      "   macro avg       0.78      0.78      0.78      5256\n",
      "weighted avg       0.78      0.78      0.78      5256\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " ...]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ANN(x_train,y_train,x_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "3fec6025",
   "metadata": {},
   "outputs": [],
   "source": [
    "###Ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f74f77ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_class0 = df2[df2['Exited']==0]\n",
    "df_class1 = df2[df2['Exited']==1]\n",
    "df_class0_1 = df_class0[:2037]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "32b85bf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_part1 = pd.concat([df_class1,df_class0_1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e4f77f32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0    2037\n",
       "0.0    2037\n",
       "Name: Exited, dtype: int64"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_part1['Exited'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "419c21b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df_part1.drop('Exited',axis=1)\n",
    "y = df_part1['Exited']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "fefce347",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train,x_test,y_train,y_test = train_test_split(x,y,test_size=0.33,random_state=45,stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "3c8a04fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "2729/2729 [==============================] - 0s 46us/sample - loss: 0.6905 - acc: 0.5394\n",
      "Epoch 2/100\n",
      "2729/2729 [==============================] - 0s 23us/sample - loss: 0.6783 - acc: 0.5636\n",
      "Epoch 3/100\n",
      "2729/2729 [==============================] - 0s 20us/sample - loss: 0.6604 - acc: 0.6032\n",
      "Epoch 4/100\n",
      "2729/2729 [==============================] - 0s 19us/sample - loss: 0.6524 - acc: 0.6218\n",
      "Epoch 5/100\n",
      "2729/2729 [==============================] - 0s 18us/sample - loss: 0.6410 - acc: 0.6347\n",
      "Epoch 6/100\n",
      "2729/2729 [==============================] - 0s 18us/sample - loss: 0.6396 - acc: 0.6438\n",
      "Epoch 7/100\n",
      "2729/2729 [==============================] - 0s 20us/sample - loss: 0.6291 - acc: 0.6479\n",
      "Epoch 8/100\n",
      "2729/2729 [==============================] - 0s 22us/sample - loss: 0.6266 - acc: 0.6526\n",
      "Epoch 9/100\n",
      "2729/2729 [==============================] - 0s 20us/sample - loss: 0.6246 - acc: 0.6632\n",
      "Epoch 10/100\n",
      "2729/2729 [==============================] - 0s 19us/sample - loss: 0.6171 - acc: 0.6643\n",
      "Epoch 11/100\n",
      "2729/2729 [==============================] - 0s 18us/sample - loss: 0.6105 - acc: 0.6731\n",
      "Epoch 12/100\n",
      "2729/2729 [==============================] - 0s 22us/sample - loss: 0.6060 - acc: 0.6720\n",
      "Epoch 13/100\n",
      "2729/2729 [==============================] - 0s 22us/sample - loss: 0.6011 - acc: 0.6830\n",
      "Epoch 14/100\n",
      "2729/2729 [==============================] - 0s 29us/sample - loss: 0.5933 - acc: 0.6911\n",
      "Epoch 15/100\n",
      "2729/2729 [==============================] - 0s 18us/sample - loss: 0.5964 - acc: 0.6856\n",
      "Epoch 16/100\n",
      "2729/2729 [==============================] - 0s 18us/sample - loss: 0.5844 - acc: 0.6962\n",
      "Epoch 17/100\n",
      "2729/2729 [==============================] - 0s 18us/sample - loss: 0.5744 - acc: 0.7050\n",
      "Epoch 18/100\n",
      "2729/2729 [==============================] - 0s 18us/sample - loss: 0.5814 - acc: 0.7025\n",
      "Epoch 19/100\n",
      "2729/2729 [==============================] - 0s 18us/sample - loss: 0.5708 - acc: 0.7156\n",
      "Epoch 20/100\n",
      "2729/2729 [==============================] - 0s 18us/sample - loss: 0.5664 - acc: 0.7288\n",
      "Epoch 21/100\n",
      "2729/2729 [==============================] - 0s 18us/sample - loss: 0.5563 - acc: 0.7230\n",
      "Epoch 22/100\n",
      "2729/2729 [==============================] - 0s 18us/sample - loss: 0.5507 - acc: 0.7303\n",
      "Epoch 23/100\n",
      "2729/2729 [==============================] - 0s 18us/sample - loss: 0.5535 - acc: 0.7321\n",
      "Epoch 24/100\n",
      "2729/2729 [==============================] - 0s 18us/sample - loss: 0.5554 - acc: 0.7266\n",
      "Epoch 25/100\n",
      "2729/2729 [==============================] - 0s 18us/sample - loss: 0.5427 - acc: 0.7417\n",
      "Epoch 26/100\n",
      "2729/2729 [==============================] - 0s 17us/sample - loss: 0.5544 - acc: 0.7307\n",
      "Epoch 27/100\n",
      "2729/2729 [==============================] - 0s 18us/sample - loss: 0.5432 - acc: 0.7398\n",
      "Epoch 28/100\n",
      "2729/2729 [==============================] - 0s 18us/sample - loss: 0.5269 - acc: 0.7519\n",
      "Epoch 29/100\n",
      "2729/2729 [==============================] - 0s 18us/sample - loss: 0.5322 - acc: 0.7373\n",
      "Epoch 30/100\n",
      "2729/2729 [==============================] - 0s 19us/sample - loss: 0.5336 - acc: 0.7428\n",
      "Epoch 31/100\n",
      "2729/2729 [==============================] - 0s 19us/sample - loss: 0.5299 - acc: 0.7369\n",
      "Epoch 32/100\n",
      "2729/2729 [==============================] - 0s 18us/sample - loss: 0.5222 - acc: 0.7442\n",
      "Epoch 33/100\n",
      "2729/2729 [==============================] - 0s 18us/sample - loss: 0.5214 - acc: 0.7406\n",
      "Epoch 34/100\n",
      "2729/2729 [==============================] - 0s 19us/sample - loss: 0.5215 - acc: 0.7486\n",
      "Epoch 35/100\n",
      "2729/2729 [==============================] - 0s 18us/sample - loss: 0.5273 - acc: 0.7457\n",
      "Epoch 36/100\n",
      "2729/2729 [==============================] - 0s 18us/sample - loss: 0.5131 - acc: 0.7571\n",
      "Epoch 37/100\n",
      "2729/2729 [==============================] - 0s 18us/sample - loss: 0.5136 - acc: 0.7578\n",
      "Epoch 38/100\n",
      "2729/2729 [==============================] - 0s 18us/sample - loss: 0.5174 - acc: 0.7530\n",
      "Epoch 39/100\n",
      "2729/2729 [==============================] - 0s 18us/sample - loss: 0.5130 - acc: 0.7582\n",
      "Epoch 40/100\n",
      "2729/2729 [==============================] - 0s 18us/sample - loss: 0.5151 - acc: 0.7545\n",
      "Epoch 41/100\n",
      "2729/2729 [==============================] - 0s 18us/sample - loss: 0.5105 - acc: 0.7538\n",
      "Epoch 42/100\n",
      "2729/2729 [==============================] - 0s 18us/sample - loss: 0.5115 - acc: 0.7574\n",
      "Epoch 43/100\n",
      "2729/2729 [==============================] - 0s 19us/sample - loss: 0.5135 - acc: 0.7556\n",
      "Epoch 44/100\n",
      "2729/2729 [==============================] - 0s 19us/sample - loss: 0.5056 - acc: 0.7589\n",
      "Epoch 45/100\n",
      "2729/2729 [==============================] - 0s 17us/sample - loss: 0.5094 - acc: 0.7519\n",
      "Epoch 46/100\n",
      "2729/2729 [==============================] - 0s 18us/sample - loss: 0.5090 - acc: 0.7585\n",
      "Epoch 47/100\n",
      "2729/2729 [==============================] - 0s 17us/sample - loss: 0.5149 - acc: 0.7505\n",
      "Epoch 48/100\n",
      "2729/2729 [==============================] - 0s 18us/sample - loss: 0.4985 - acc: 0.7655\n",
      "Epoch 49/100\n",
      "2729/2729 [==============================] - 0s 18us/sample - loss: 0.5075 - acc: 0.7567\n",
      "Epoch 50/100\n",
      "2729/2729 [==============================] - 0s 19us/sample - loss: 0.4971 - acc: 0.7545\n",
      "Epoch 51/100\n",
      "2729/2729 [==============================] - 0s 20us/sample - loss: 0.4992 - acc: 0.7549\n",
      "Epoch 52/100\n",
      "2729/2729 [==============================] - 0s 19us/sample - loss: 0.5110 - acc: 0.7519\n",
      "Epoch 53/100\n",
      "2729/2729 [==============================] - 0s 18us/sample - loss: 0.5039 - acc: 0.7655\n",
      "Epoch 54/100\n",
      "2729/2729 [==============================] - 0s 18us/sample - loss: 0.5000 - acc: 0.7669\n",
      "Epoch 55/100\n",
      "2729/2729 [==============================] - 0s 21us/sample - loss: 0.4937 - acc: 0.7589\n",
      "Epoch 56/100\n",
      "2729/2729 [==============================] - 0s 22us/sample - loss: 0.5008 - acc: 0.7618\n",
      "Epoch 57/100\n",
      "2729/2729 [==============================] - 0s 19us/sample - loss: 0.5061 - acc: 0.7615\n",
      "Epoch 58/100\n",
      "2729/2729 [==============================] - 0s 20us/sample - loss: 0.4966 - acc: 0.7615\n",
      "Epoch 59/100\n",
      "2729/2729 [==============================] - 0s 18us/sample - loss: 0.4989 - acc: 0.7549\n",
      "Epoch 60/100\n",
      "2729/2729 [==============================] - 0s 18us/sample - loss: 0.4953 - acc: 0.7651\n",
      "Epoch 61/100\n",
      "2729/2729 [==============================] - 0s 20us/sample - loss: 0.4927 - acc: 0.7574\n",
      "Epoch 62/100\n",
      "2729/2729 [==============================] - 0s 22us/sample - loss: 0.4869 - acc: 0.7717\n",
      "Epoch 63/100\n",
      "2729/2729 [==============================] - 0s 20us/sample - loss: 0.4932 - acc: 0.7578\n",
      "Epoch 64/100\n",
      "2729/2729 [==============================] - 0s 22us/sample - loss: 0.4922 - acc: 0.7611\n",
      "Epoch 65/100\n",
      "2729/2729 [==============================] - 0s 18us/sample - loss: 0.4932 - acc: 0.7585\n",
      "Epoch 66/100\n",
      "2729/2729 [==============================] - 0s 21us/sample - loss: 0.4994 - acc: 0.7582\n",
      "Epoch 67/100\n",
      "2729/2729 [==============================] - 0s 17us/sample - loss: 0.4871 - acc: 0.7512\n",
      "Epoch 68/100\n",
      "2729/2729 [==============================] - 0s 25us/sample - loss: 0.4927 - acc: 0.7607\n",
      "Epoch 69/100\n",
      "2729/2729 [==============================] - 0s 17us/sample - loss: 0.4870 - acc: 0.7658\n",
      "Epoch 70/100\n",
      "2729/2729 [==============================] - 0s 20us/sample - loss: 0.4959 - acc: 0.7673\n",
      "Epoch 71/100\n",
      "2729/2729 [==============================] - 0s 18us/sample - loss: 0.4891 - acc: 0.7582\n",
      "Epoch 72/100\n",
      "2729/2729 [==============================] - 0s 21us/sample - loss: 0.4865 - acc: 0.7684\n",
      "Epoch 73/100\n",
      "2729/2729 [==============================] - 0s 18us/sample - loss: 0.4931 - acc: 0.7651\n",
      "Epoch 74/100\n",
      "2729/2729 [==============================] - 0s 18us/sample - loss: 0.4888 - acc: 0.7746\n",
      "Epoch 75/100\n",
      "2729/2729 [==============================] - 0s 19us/sample - loss: 0.4916 - acc: 0.7644\n",
      "Epoch 76/100\n",
      "2729/2729 [==============================] - 0s 21us/sample - loss: 0.4971 - acc: 0.7626\n",
      "Epoch 77/100\n",
      "2729/2729 [==============================] - 0s 18us/sample - loss: 0.4845 - acc: 0.7706\n",
      "Epoch 78/100\n",
      "2729/2729 [==============================] - 0s 19us/sample - loss: 0.4939 - acc: 0.7578\n",
      "Epoch 79/100\n",
      "2729/2729 [==============================] - 0s 19us/sample - loss: 0.4843 - acc: 0.7699\n",
      "Epoch 80/100\n",
      "2729/2729 [==============================] - 0s 19us/sample - loss: 0.4844 - acc: 0.7618\n",
      "Epoch 81/100\n",
      "2729/2729 [==============================] - 0s 19us/sample - loss: 0.4791 - acc: 0.7728\n",
      "Epoch 82/100\n",
      "2729/2729 [==============================] - 0s 20us/sample - loss: 0.4873 - acc: 0.7680\n",
      "Epoch 83/100\n",
      "2729/2729 [==============================] - 0s 18us/sample - loss: 0.4800 - acc: 0.7600\n",
      "Epoch 84/100\n",
      "2729/2729 [==============================] - 0s 22us/sample - loss: 0.4812 - acc: 0.7739\n",
      "Epoch 85/100\n",
      "2729/2729 [==============================] - 0s 19us/sample - loss: 0.4822 - acc: 0.7615\n",
      "Epoch 86/100\n",
      "2729/2729 [==============================] - 0s 18us/sample - loss: 0.4842 - acc: 0.7633\n",
      "Epoch 87/100\n",
      "2729/2729 [==============================] - 0s 18us/sample - loss: 0.4854 - acc: 0.7615\n",
      "Epoch 88/100\n",
      "2729/2729 [==============================] - 0s 19us/sample - loss: 0.4860 - acc: 0.7651\n",
      "Epoch 89/100\n",
      "2729/2729 [==============================] - 0s 20us/sample - loss: 0.4770 - acc: 0.7640\n",
      "Epoch 90/100\n",
      "2729/2729 [==============================] - 0s 18us/sample - loss: 0.4868 - acc: 0.7669\n",
      "Epoch 91/100\n",
      "2729/2729 [==============================] - 0s 18us/sample - loss: 0.4833 - acc: 0.7611\n",
      "Epoch 92/100\n",
      "2729/2729 [==============================] - 0s 20us/sample - loss: 0.4858 - acc: 0.7651\n",
      "Epoch 93/100\n",
      "2729/2729 [==============================] - 0s 22us/sample - loss: 0.4778 - acc: 0.7622\n",
      "Epoch 94/100\n",
      "2729/2729 [==============================] - 0s 19us/sample - loss: 0.4764 - acc: 0.7647\n",
      "Epoch 95/100\n",
      "2729/2729 [==============================] - 0s 18us/sample - loss: 0.4796 - acc: 0.7655\n",
      "Epoch 96/100\n",
      "2729/2729 [==============================] - 0s 19us/sample - loss: 0.4924 - acc: 0.7666\n",
      "Epoch 97/100\n",
      "2729/2729 [==============================] - 0s 22us/sample - loss: 0.4706 - acc: 0.7754\n",
      "Epoch 98/100\n",
      "2729/2729 [==============================] - 0s 23us/sample - loss: 0.4705 - acc: 0.7666\n",
      "Epoch 99/100\n",
      "2729/2729 [==============================] - 0s 22us/sample - loss: 0.4858 - acc: 0.7658\n",
      "Epoch 100/100\n",
      "2729/2729 [==============================] - 0s 18us/sample - loss: 0.4742 - acc: 0.7728\n",
      "1345/1345 [==============================] - 0s 24us/sample - loss: 0.4821 - acc: 0.7591\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.78      0.72      0.75       672\n",
      "         1.0       0.74      0.80      0.77       673\n",
      "\n",
      "    accuracy                           0.76      1345\n",
      "   macro avg       0.76      0.76      0.76      1345\n",
      "weighted avg       0.76      0.76      0.76      1345\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred1 = ANN(x_train,y_train,x_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "60744e5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_class0 = df2[df2['Exited']==0]\n",
    "df_class1 = df2[df2['Exited']==1]\n",
    "df_class0_2 = df_class0[2037:4074]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "7ec2e699",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_part2 = pd.concat([df_class1,df_class0_2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "3773bbde",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0    2037\n",
       "0.0    2037\n",
       "Name: Exited, dtype: int64"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_part2['Exited'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "1e375fe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df_part2.drop('Exited',axis=1)\n",
    "y = df_part2['Exited']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "5d7d68e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train,x_test,y_train,y_test = train_test_split(x,y,test_size=0.33,random_state=45,stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "dedd4a6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "2729/2729 [==============================] - 0s 48us/sample - loss: 0.6893 - acc: 0.5416\n",
      "Epoch 2/100\n",
      "2729/2729 [==============================] - 0s 20us/sample - loss: 0.6608 - acc: 0.6024\n",
      "Epoch 3/100\n",
      "2729/2729 [==============================] - 0s 22us/sample - loss: 0.6590 - acc: 0.6211\n",
      "Epoch 4/100\n",
      "2729/2729 [==============================] - 0s 19us/sample - loss: 0.6540 - acc: 0.6295\n",
      "Epoch 5/100\n",
      "2729/2729 [==============================] - 0s 19us/sample - loss: 0.6475 - acc: 0.6270\n",
      "Epoch 6/100\n",
      "2729/2729 [==============================] - 0s 18us/sample - loss: 0.6370 - acc: 0.6405\n",
      "Epoch 7/100\n",
      "2729/2729 [==============================] - 0s 18us/sample - loss: 0.6357 - acc: 0.6387\n",
      "Epoch 8/100\n",
      "2729/2729 [==============================] - 0s 18us/sample - loss: 0.6200 - acc: 0.6610\n",
      "Epoch 9/100\n",
      "2729/2729 [==============================] - 0s 18us/sample - loss: 0.6166 - acc: 0.6640\n",
      "Epoch 10/100\n",
      "2729/2729 [==============================] - 0s 18us/sample - loss: 0.6163 - acc: 0.6695\n",
      "Epoch 11/100\n",
      "2729/2729 [==============================] - 0s 19us/sample - loss: 0.6068 - acc: 0.6867\n",
      "Epoch 12/100\n",
      "2729/2729 [==============================] - 0s 21us/sample - loss: 0.6116 - acc: 0.6779\n",
      "Epoch 13/100\n",
      "2729/2729 [==============================] - 0s 24us/sample - loss: 0.6020 - acc: 0.6819\n",
      "Epoch 14/100\n",
      "2729/2729 [==============================] - 0s 20us/sample - loss: 0.5942 - acc: 0.6981\n",
      "Epoch 15/100\n",
      "2729/2729 [==============================] - 0s 18us/sample - loss: 0.5932 - acc: 0.6955\n",
      "Epoch 16/100\n",
      "2729/2729 [==============================] - 0s 19us/sample - loss: 0.5800 - acc: 0.7109\n",
      "Epoch 17/100\n",
      "2729/2729 [==============================] - 0s 19us/sample - loss: 0.5697 - acc: 0.7043\n",
      "Epoch 18/100\n",
      "2729/2729 [==============================] - 0s 19us/sample - loss: 0.5692 - acc: 0.7193\n",
      "Epoch 19/100\n",
      "2729/2729 [==============================] - 0s 18us/sample - loss: 0.5586 - acc: 0.7160\n",
      "Epoch 20/100\n",
      "2729/2729 [==============================] - 0s 20us/sample - loss: 0.5559 - acc: 0.7204\n",
      "Epoch 21/100\n",
      "2729/2729 [==============================] - 0s 19us/sample - loss: 0.5469 - acc: 0.7420\n",
      "Epoch 22/100\n",
      "2729/2729 [==============================] - 0s 19us/sample - loss: 0.5456 - acc: 0.7314\n",
      "Epoch 23/100\n",
      "2729/2729 [==============================] - 0s 19us/sample - loss: 0.5476 - acc: 0.7314\n",
      "Epoch 24/100\n",
      "2729/2729 [==============================] - 0s 20us/sample - loss: 0.5376 - acc: 0.7384\n",
      "Epoch 25/100\n",
      "2729/2729 [==============================] - 0s 19us/sample - loss: 0.5371 - acc: 0.7457\n",
      "Epoch 26/100\n",
      "2729/2729 [==============================] - 0s 22us/sample - loss: 0.5425 - acc: 0.7409\n",
      "Epoch 27/100\n",
      "2729/2729 [==============================] - 0s 20us/sample - loss: 0.5329 - acc: 0.7395\n",
      "Epoch 28/100\n",
      "2729/2729 [==============================] - 0s 17us/sample - loss: 0.5381 - acc: 0.7439\n",
      "Epoch 29/100\n",
      "2729/2729 [==============================] - 0s 22us/sample - loss: 0.5246 - acc: 0.7534\n",
      "Epoch 30/100\n",
      "2729/2729 [==============================] - 0s 19us/sample - loss: 0.5357 - acc: 0.7435\n",
      "Epoch 31/100\n",
      "2729/2729 [==============================] - 0s 19us/sample - loss: 0.5257 - acc: 0.7494\n",
      "Epoch 32/100\n",
      "2729/2729 [==============================] - 0s 18us/sample - loss: 0.5248 - acc: 0.7461\n",
      "Epoch 33/100\n",
      "2729/2729 [==============================] - 0s 18us/sample - loss: 0.5291 - acc: 0.7417\n",
      "Epoch 34/100\n",
      "2729/2729 [==============================] - 0s 18us/sample - loss: 0.5208 - acc: 0.7556\n",
      "Epoch 35/100\n",
      "2729/2729 [==============================] - 0s 19us/sample - loss: 0.5270 - acc: 0.7593\n",
      "Epoch 36/100\n",
      "2729/2729 [==============================] - 0s 19us/sample - loss: 0.5262 - acc: 0.7604\n",
      "Epoch 37/100\n",
      "2729/2729 [==============================] - 0s 20us/sample - loss: 0.5158 - acc: 0.7571\n",
      "Epoch 38/100\n",
      "2729/2729 [==============================] - 0s 19us/sample - loss: 0.5228 - acc: 0.7541\n",
      "Epoch 39/100\n",
      "2729/2729 [==============================] - 0s 19us/sample - loss: 0.5198 - acc: 0.7563\n",
      "Epoch 40/100\n",
      "2729/2729 [==============================] - 0s 18us/sample - loss: 0.5237 - acc: 0.7402\n",
      "Epoch 41/100\n",
      "2729/2729 [==============================] - 0s 20us/sample - loss: 0.5136 - acc: 0.7622\n",
      "Epoch 42/100\n",
      "2729/2729 [==============================] - 0s 18us/sample - loss: 0.5223 - acc: 0.7622\n",
      "Epoch 43/100\n",
      "2729/2729 [==============================] - 0s 19us/sample - loss: 0.5120 - acc: 0.7604\n",
      "Epoch 44/100\n",
      "2729/2729 [==============================] - 0s 18us/sample - loss: 0.5188 - acc: 0.7545\n",
      "Epoch 45/100\n",
      "2729/2729 [==============================] - 0s 19us/sample - loss: 0.5112 - acc: 0.7589\n",
      "Epoch 46/100\n",
      "2729/2729 [==============================] - 0s 23us/sample - loss: 0.5073 - acc: 0.7567\n",
      "Epoch 47/100\n",
      "2729/2729 [==============================] - 0s 20us/sample - loss: 0.5178 - acc: 0.7541\n",
      "Epoch 48/100\n",
      "2729/2729 [==============================] - 0s 18us/sample - loss: 0.5127 - acc: 0.7578\n",
      "Epoch 49/100\n",
      "2729/2729 [==============================] - 0s 18us/sample - loss: 0.5101 - acc: 0.7563\n",
      "Epoch 50/100\n",
      "2729/2729 [==============================] - 0s 19us/sample - loss: 0.5168 - acc: 0.7585\n",
      "Epoch 51/100\n",
      "2729/2729 [==============================] - 0s 18us/sample - loss: 0.5083 - acc: 0.7691\n",
      "Epoch 52/100\n",
      "2729/2729 [==============================] - 0s 22us/sample - loss: 0.4974 - acc: 0.7512\n",
      "Epoch 53/100\n",
      "2729/2729 [==============================] - 0s 19us/sample - loss: 0.5075 - acc: 0.7563\n",
      "Epoch 54/100\n",
      "2729/2729 [==============================] - 0s 18us/sample - loss: 0.5124 - acc: 0.7596\n",
      "Epoch 55/100\n",
      "2729/2729 [==============================] - 0s 18us/sample - loss: 0.5209 - acc: 0.7589\n",
      "Epoch 56/100\n",
      "2729/2729 [==============================] - 0s 18us/sample - loss: 0.5111 - acc: 0.7604\n",
      "Epoch 57/100\n",
      "2729/2729 [==============================] - 0s 18us/sample - loss: 0.5015 - acc: 0.7644\n",
      "Epoch 58/100\n",
      "2729/2729 [==============================] - 0s 18us/sample - loss: 0.5012 - acc: 0.7655\n",
      "Epoch 59/100\n",
      "2729/2729 [==============================] - 0s 18us/sample - loss: 0.5076 - acc: 0.7658\n",
      "Epoch 60/100\n",
      "2729/2729 [==============================] - 0s 18us/sample - loss: 0.5019 - acc: 0.7618\n",
      "Epoch 61/100\n",
      "2729/2729 [==============================] - 0s 19us/sample - loss: 0.5074 - acc: 0.7688\n",
      "Epoch 62/100\n",
      "2729/2729 [==============================] - 0s 19us/sample - loss: 0.4963 - acc: 0.7618\n",
      "Epoch 63/100\n",
      "2729/2729 [==============================] - 0s 18us/sample - loss: 0.4994 - acc: 0.7677\n",
      "Epoch 64/100\n",
      "2729/2729 [==============================] - 0s 18us/sample - loss: 0.4991 - acc: 0.7695\n",
      "Epoch 65/100\n",
      "2729/2729 [==============================] - 0s 21us/sample - loss: 0.5024 - acc: 0.7600\n",
      "Epoch 66/100\n",
      "2729/2729 [==============================] - 0s 16us/sample - loss: 0.4997 - acc: 0.7669\n",
      "Epoch 67/100\n",
      "2729/2729 [==============================] - 0s 22us/sample - loss: 0.4875 - acc: 0.7677\n",
      "Epoch 68/100\n",
      "2729/2729 [==============================] - 0s 19us/sample - loss: 0.5030 - acc: 0.7629\n",
      "Epoch 69/100\n",
      "2729/2729 [==============================] - 0s 18us/sample - loss: 0.5047 - acc: 0.7724\n",
      "Epoch 70/100\n",
      "2729/2729 [==============================] - 0s 18us/sample - loss: 0.5052 - acc: 0.7680\n",
      "Epoch 71/100\n",
      "2729/2729 [==============================] - 0s 18us/sample - loss: 0.4972 - acc: 0.7772\n",
      "Epoch 72/100\n",
      "2729/2729 [==============================] - 0s 18us/sample - loss: 0.4942 - acc: 0.7688\n",
      "Epoch 73/100\n",
      "2729/2729 [==============================] - 0s 19us/sample - loss: 0.4977 - acc: 0.7666\n",
      "Epoch 74/100\n",
      "2729/2729 [==============================] - 0s 18us/sample - loss: 0.5041 - acc: 0.7651\n",
      "Epoch 75/100\n",
      "2729/2729 [==============================] - 0s 18us/sample - loss: 0.4940 - acc: 0.7604\n",
      "Epoch 76/100\n",
      "2729/2729 [==============================] - 0s 18us/sample - loss: 0.4928 - acc: 0.7680\n",
      "Epoch 77/100\n",
      "2729/2729 [==============================] - 0s 23us/sample - loss: 0.5020 - acc: 0.7677\n",
      "Epoch 78/100\n",
      "2729/2729 [==============================] - 0s 18us/sample - loss: 0.4876 - acc: 0.7732\n",
      "Epoch 79/100\n",
      "2729/2729 [==============================] - 0s 18us/sample - loss: 0.4964 - acc: 0.7739\n",
      "Epoch 80/100\n",
      "2729/2729 [==============================] - 0s 18us/sample - loss: 0.5008 - acc: 0.7666\n",
      "Epoch 81/100\n",
      "2729/2729 [==============================] - 0s 17us/sample - loss: 0.4917 - acc: 0.7710\n",
      "Epoch 82/100\n",
      "2729/2729 [==============================] - 0s 19us/sample - loss: 0.4911 - acc: 0.7662\n",
      "Epoch 83/100\n",
      "2729/2729 [==============================] - 0s 18us/sample - loss: 0.4941 - acc: 0.7662\n",
      "Epoch 84/100\n",
      "2729/2729 [==============================] - 0s 18us/sample - loss: 0.4884 - acc: 0.7651\n",
      "Epoch 85/100\n",
      "2729/2729 [==============================] - 0s 18us/sample - loss: 0.4891 - acc: 0.7746\n",
      "Epoch 86/100\n",
      "2729/2729 [==============================] - 0s 19us/sample - loss: 0.4880 - acc: 0.7713\n",
      "Epoch 87/100\n",
      "2729/2729 [==============================] - 0s 18us/sample - loss: 0.4963 - acc: 0.7732\n",
      "Epoch 88/100\n",
      "2729/2729 [==============================] - 0s 18us/sample - loss: 0.4873 - acc: 0.7754\n",
      "Epoch 89/100\n",
      "2729/2729 [==============================] - 0s 17us/sample - loss: 0.4886 - acc: 0.7721\n",
      "Epoch 90/100\n",
      "2729/2729 [==============================] - 0s 18us/sample - loss: 0.4943 - acc: 0.7629\n",
      "Epoch 91/100\n",
      "2729/2729 [==============================] - 0s 18us/sample - loss: 0.5045 - acc: 0.7578\n",
      "Epoch 92/100\n",
      "2729/2729 [==============================] - 0s 18us/sample - loss: 0.4861 - acc: 0.7680\n",
      "Epoch 93/100\n",
      "2729/2729 [==============================] - 0s 18us/sample - loss: 0.4861 - acc: 0.7746\n",
      "Epoch 94/100\n",
      "2729/2729 [==============================] - 0s 18us/sample - loss: 0.4943 - acc: 0.7801\n",
      "Epoch 95/100\n",
      "2729/2729 [==============================] - 0s 18us/sample - loss: 0.4866 - acc: 0.7746\n",
      "Epoch 96/100\n",
      "2729/2729 [==============================] - 0s 18us/sample - loss: 0.4938 - acc: 0.7673\n",
      "Epoch 97/100\n",
      "2729/2729 [==============================] - 0s 18us/sample - loss: 0.4832 - acc: 0.7754\n",
      "Epoch 98/100\n",
      "2729/2729 [==============================] - 0s 18us/sample - loss: 0.4892 - acc: 0.7743\n",
      "Epoch 99/100\n",
      "2729/2729 [==============================] - 0s 18us/sample - loss: 0.4795 - acc: 0.7772\n",
      "Epoch 100/100\n",
      "2729/2729 [==============================] - 0s 21us/sample - loss: 0.4952 - acc: 0.7713\n",
      "1345/1345 [==============================] - 0s 38us/sample - loss: 0.4755 - acc: 0.7651\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.75      0.81      0.77       672\n",
      "         1.0       0.79      0.73      0.76       673\n",
      "\n",
      "    accuracy                           0.77      1345\n",
      "   macro avg       0.77      0.77      0.76      1345\n",
      "weighted avg       0.77      0.77      0.76      1345\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred2 = ANN(x_train,y_train,x_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "f0c22675",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_class0 = df2[df2['Exited']==0]\n",
    "df_class1 = df2[df2['Exited']==1]\n",
    "df_class0_3 = df_class0[4074:6111]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "30fc3530",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_part3 = pd.concat([df_class1,df_class0_3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "93cc41c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0    2037\n",
       "0.0    2037\n",
       "Name: Exited, dtype: int64"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_part3['Exited'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "0da68d46",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df_part3.drop('Exited',axis=1)\n",
    "y = df_part3['Exited']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "ff5042fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train,x_test,y_train,y_test = train_test_split(x,y,test_size=0.33,random_state=45,stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "00bf996b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "2729/2729 [==============================] - 0s 49us/sample - loss: 0.6841 - acc: 0.5405\n",
      "Epoch 2/100\n",
      "2729/2729 [==============================] - 0s 22us/sample - loss: 0.6681 - acc: 0.5980\n",
      "Epoch 3/100\n",
      "2729/2729 [==============================] - 0s 20us/sample - loss: 0.6465 - acc: 0.6266\n",
      "Epoch 4/100\n",
      "2729/2729 [==============================] - 0s 21us/sample - loss: 0.6496 - acc: 0.6270\n",
      "Epoch 5/100\n",
      "2729/2729 [==============================] - 0s 20us/sample - loss: 0.6331 - acc: 0.6497\n",
      "Epoch 6/100\n",
      "2729/2729 [==============================] - 0s 21us/sample - loss: 0.6272 - acc: 0.6530\n",
      "Epoch 7/100\n",
      "2729/2729 [==============================] - 0s 19us/sample - loss: 0.6186 - acc: 0.6709\n",
      "Epoch 8/100\n",
      "2729/2729 [==============================] - 0s 21us/sample - loss: 0.6184 - acc: 0.6728\n",
      "Epoch 9/100\n",
      "2729/2729 [==============================] - 0s 22us/sample - loss: 0.6130 - acc: 0.6753\n",
      "Epoch 10/100\n",
      "2729/2729 [==============================] - 0s 21us/sample - loss: 0.6006 - acc: 0.6863\n",
      "Epoch 11/100\n",
      "2729/2729 [==============================] - 0s 19us/sample - loss: 0.6006 - acc: 0.6977\n",
      "Epoch 12/100\n",
      "2729/2729 [==============================] - 0s 20us/sample - loss: 0.5927 - acc: 0.6926\n",
      "Epoch 13/100\n",
      "2729/2729 [==============================] - 0s 20us/sample - loss: 0.5825 - acc: 0.6992\n",
      "Epoch 14/100\n",
      "2729/2729 [==============================] - 0s 18us/sample - loss: 0.5853 - acc: 0.7050\n",
      "Epoch 15/100\n",
      "2729/2729 [==============================] - 0s 17us/sample - loss: 0.5794 - acc: 0.7025\n",
      "Epoch 16/100\n",
      "2729/2729 [==============================] - 0s 21us/sample - loss: 0.5767 - acc: 0.7131\n",
      "Epoch 17/100\n",
      "2729/2729 [==============================] - 0s 18us/sample - loss: 0.5652 - acc: 0.7182\n",
      "Epoch 18/100\n",
      "2729/2729 [==============================] - 0s 19us/sample - loss: 0.5659 - acc: 0.7167\n",
      "Epoch 19/100\n",
      "2729/2729 [==============================] - 0s 22us/sample - loss: 0.5637 - acc: 0.7318\n",
      "Epoch 20/100\n",
      "2729/2729 [==============================] - 0s 20us/sample - loss: 0.5570 - acc: 0.7314\n",
      "Epoch 21/100\n",
      "2729/2729 [==============================] - 0s 19us/sample - loss: 0.5610 - acc: 0.7255\n",
      "Epoch 22/100\n",
      "2729/2729 [==============================] - 0s 18us/sample - loss: 0.5556 - acc: 0.7347\n",
      "Epoch 23/100\n",
      "2729/2729 [==============================] - 0s 18us/sample - loss: 0.5496 - acc: 0.7347\n",
      "Epoch 24/100\n",
      "2729/2729 [==============================] - 0s 20us/sample - loss: 0.5431 - acc: 0.7358\n",
      "Epoch 25/100\n",
      "2729/2729 [==============================] - 0s 19us/sample - loss: 0.5436 - acc: 0.7431\n",
      "Epoch 26/100\n",
      "2729/2729 [==============================] - 0s 20us/sample - loss: 0.5474 - acc: 0.7413\n",
      "Epoch 27/100\n",
      "2729/2729 [==============================] - 0s 21us/sample - loss: 0.5350 - acc: 0.7530\n",
      "Epoch 28/100\n",
      "2729/2729 [==============================] - 0s 19us/sample - loss: 0.5307 - acc: 0.7391\n",
      "Epoch 29/100\n",
      "2729/2729 [==============================] - 0s 19us/sample - loss: 0.5389 - acc: 0.7402\n",
      "Epoch 30/100\n",
      "2729/2729 [==============================] - 0s 20us/sample - loss: 0.5399 - acc: 0.7512\n",
      "Epoch 31/100\n",
      "2729/2729 [==============================] - 0s 20us/sample - loss: 0.5315 - acc: 0.7549\n",
      "Epoch 32/100\n",
      "2729/2729 [==============================] - 0s 20us/sample - loss: 0.5242 - acc: 0.7574\n",
      "Epoch 33/100\n",
      "2729/2729 [==============================] - 0s 19us/sample - loss: 0.5297 - acc: 0.7505\n",
      "Epoch 34/100\n",
      "2729/2729 [==============================] - 0s 21us/sample - loss: 0.5199 - acc: 0.7574\n",
      "Epoch 35/100\n",
      "2729/2729 [==============================] - 0s 19us/sample - loss: 0.5235 - acc: 0.7508\n",
      "Epoch 36/100\n",
      "2729/2729 [==============================] - 0s 19us/sample - loss: 0.5236 - acc: 0.7534\n",
      "Epoch 37/100\n",
      "2729/2729 [==============================] - 0s 19us/sample - loss: 0.5163 - acc: 0.7556\n",
      "Epoch 38/100\n",
      "2729/2729 [==============================] - 0s 19us/sample - loss: 0.5204 - acc: 0.7468\n",
      "Epoch 39/100\n",
      "2729/2729 [==============================] - 0s 20us/sample - loss: 0.5071 - acc: 0.7589\n",
      "Epoch 40/100\n",
      "2729/2729 [==============================] - 0s 19us/sample - loss: 0.5082 - acc: 0.7604\n",
      "Epoch 41/100\n",
      "2729/2729 [==============================] - 0s 18us/sample - loss: 0.5088 - acc: 0.7589\n",
      "Epoch 42/100\n",
      "2729/2729 [==============================] - 0s 20us/sample - loss: 0.5119 - acc: 0.7505\n",
      "Epoch 43/100\n",
      "2729/2729 [==============================] - 0s 20us/sample - loss: 0.5145 - acc: 0.7574\n",
      "Epoch 44/100\n",
      "2729/2729 [==============================] - 0s 19us/sample - loss: 0.5030 - acc: 0.7651\n",
      "Epoch 45/100\n",
      "2729/2729 [==============================] - 0s 19us/sample - loss: 0.5049 - acc: 0.7651\n",
      "Epoch 46/100\n",
      "2729/2729 [==============================] - 0s 19us/sample - loss: 0.4998 - acc: 0.7644\n",
      "Epoch 47/100\n",
      "2729/2729 [==============================] - 0s 18us/sample - loss: 0.4989 - acc: 0.7644\n",
      "Epoch 48/100\n",
      "2729/2729 [==============================] - 0s 19us/sample - loss: 0.5119 - acc: 0.7611\n",
      "Epoch 49/100\n",
      "2729/2729 [==============================] - 0s 20us/sample - loss: 0.5055 - acc: 0.7673\n",
      "Epoch 50/100\n",
      "2729/2729 [==============================] - 0s 18us/sample - loss: 0.5002 - acc: 0.7600\n",
      "Epoch 51/100\n",
      "2729/2729 [==============================] - 0s 18us/sample - loss: 0.4999 - acc: 0.7589\n",
      "Epoch 52/100\n",
      "2729/2729 [==============================] - 0s 18us/sample - loss: 0.4971 - acc: 0.7662\n",
      "Epoch 53/100\n",
      "2729/2729 [==============================] - 0s 18us/sample - loss: 0.5009 - acc: 0.7644\n",
      "Epoch 54/100\n",
      "2729/2729 [==============================] - 0s 19us/sample - loss: 0.4997 - acc: 0.7585\n",
      "Epoch 55/100\n",
      "2729/2729 [==============================] - 0s 19us/sample - loss: 0.5012 - acc: 0.7640\n",
      "Epoch 56/100\n",
      "2729/2729 [==============================] - 0s 18us/sample - loss: 0.5063 - acc: 0.7563\n",
      "Epoch 57/100\n",
      "2729/2729 [==============================] - 0s 19us/sample - loss: 0.4982 - acc: 0.7724\n",
      "Epoch 58/100\n",
      "2729/2729 [==============================] - 0s 20us/sample - loss: 0.4986 - acc: 0.7640\n",
      "Epoch 59/100\n",
      "2729/2729 [==============================] - 0s 18us/sample - loss: 0.4969 - acc: 0.7658\n",
      "Epoch 60/100\n",
      "2729/2729 [==============================] - 0s 22us/sample - loss: 0.4979 - acc: 0.7633\n",
      "Epoch 61/100\n",
      "2729/2729 [==============================] - 0s 20us/sample - loss: 0.4992 - acc: 0.7662\n",
      "Epoch 62/100\n",
      "2729/2729 [==============================] - 0s 18us/sample - loss: 0.4926 - acc: 0.7618\n",
      "Epoch 63/100\n",
      "2729/2729 [==============================] - 0s 21us/sample - loss: 0.5016 - acc: 0.7611\n",
      "Epoch 64/100\n",
      "2729/2729 [==============================] - 0s 19us/sample - loss: 0.4985 - acc: 0.7618\n",
      "Epoch 65/100\n",
      "2729/2729 [==============================] - 0s 21us/sample - loss: 0.4956 - acc: 0.7666\n",
      "Epoch 66/100\n",
      "2729/2729 [==============================] - 0s 20us/sample - loss: 0.4966 - acc: 0.7677\n",
      "Epoch 67/100\n",
      "2729/2729 [==============================] - 0s 18us/sample - loss: 0.4887 - acc: 0.7633\n",
      "Epoch 68/100\n",
      "2729/2729 [==============================] - 0s 18us/sample - loss: 0.4968 - acc: 0.7626\n",
      "Epoch 69/100\n",
      "2729/2729 [==============================] - 0s 20us/sample - loss: 0.4942 - acc: 0.7732\n",
      "Epoch 70/100\n",
      "2729/2729 [==============================] - 0s 19us/sample - loss: 0.4927 - acc: 0.7706\n",
      "Epoch 71/100\n",
      "2729/2729 [==============================] - 0s 18us/sample - loss: 0.4961 - acc: 0.7666\n",
      "Epoch 72/100\n",
      "2729/2729 [==============================] - 0s 18us/sample - loss: 0.4903 - acc: 0.7684\n",
      "Epoch 73/100\n",
      "2729/2729 [==============================] - 0s 19us/sample - loss: 0.4951 - acc: 0.7669\n",
      "Epoch 74/100\n",
      "2729/2729 [==============================] - 0s 18us/sample - loss: 0.4854 - acc: 0.7644\n",
      "Epoch 75/100\n",
      "2729/2729 [==============================] - 0s 19us/sample - loss: 0.5022 - acc: 0.7680\n",
      "Epoch 76/100\n",
      "2729/2729 [==============================] - 0s 19us/sample - loss: 0.4831 - acc: 0.7772\n",
      "Epoch 77/100\n",
      "2729/2729 [==============================] - 0s 19us/sample - loss: 0.4878 - acc: 0.7662\n",
      "Epoch 78/100\n",
      "2729/2729 [==============================] - 0s 18us/sample - loss: 0.4853 - acc: 0.7622\n",
      "Epoch 79/100\n",
      "2729/2729 [==============================] - 0s 18us/sample - loss: 0.4784 - acc: 0.7710\n",
      "Epoch 80/100\n",
      "2729/2729 [==============================] - 0s 18us/sample - loss: 0.4810 - acc: 0.7673\n",
      "Epoch 81/100\n",
      "2729/2729 [==============================] - 0s 23us/sample - loss: 0.4834 - acc: 0.7772\n",
      "Epoch 82/100\n",
      "2729/2729 [==============================] - 0s 19us/sample - loss: 0.4903 - acc: 0.7702\n",
      "Epoch 83/100\n",
      "2729/2729 [==============================] - 0s 18us/sample - loss: 0.4874 - acc: 0.7680\n",
      "Epoch 84/100\n",
      "2729/2729 [==============================] - 0s 23us/sample - loss: 0.4858 - acc: 0.7735\n",
      "Epoch 85/100\n",
      "2729/2729 [==============================] - 0s 20us/sample - loss: 0.4852 - acc: 0.7666\n",
      "Epoch 86/100\n",
      "2729/2729 [==============================] - 0s 21us/sample - loss: 0.4834 - acc: 0.7684\n",
      "Epoch 87/100\n",
      "2729/2729 [==============================] - 0s 34us/sample - loss: 0.4763 - acc: 0.7735\n",
      "Epoch 88/100\n",
      "2729/2729 [==============================] - 0s 21us/sample - loss: 0.4869 - acc: 0.7710\n",
      "Epoch 89/100\n",
      "2729/2729 [==============================] - 0s 22us/sample - loss: 0.4955 - acc: 0.7677\n",
      "Epoch 90/100\n",
      "2729/2729 [==============================] - 0s 19us/sample - loss: 0.4907 - acc: 0.7662\n",
      "Epoch 91/100\n",
      "2729/2729 [==============================] - 0s 21us/sample - loss: 0.4999 - acc: 0.7699\n",
      "Epoch 92/100\n",
      "2729/2729 [==============================] - 0s 19us/sample - loss: 0.4852 - acc: 0.7684\n",
      "Epoch 93/100\n",
      "2729/2729 [==============================] - 0s 22us/sample - loss: 0.4944 - acc: 0.7695\n",
      "Epoch 94/100\n",
      "2729/2729 [==============================] - 0s 20us/sample - loss: 0.4890 - acc: 0.7710\n",
      "Epoch 95/100\n",
      "2729/2729 [==============================] - 0s 21us/sample - loss: 0.4866 - acc: 0.7695\n",
      "Epoch 96/100\n",
      "2729/2729 [==============================] - 0s 19us/sample - loss: 0.4880 - acc: 0.7662\n",
      "Epoch 97/100\n",
      "2729/2729 [==============================] - 0s 18us/sample - loss: 0.4826 - acc: 0.7743\n",
      "Epoch 98/100\n",
      "2729/2729 [==============================] - 0s 22us/sample - loss: 0.4821 - acc: 0.7735\n",
      "Epoch 99/100\n",
      "2729/2729 [==============================] - 0s 19us/sample - loss: 0.4809 - acc: 0.7691\n",
      "Epoch 100/100\n",
      "2729/2729 [==============================] - 0s 22us/sample - loss: 0.4780 - acc: 0.7717\n",
      "1345/1345 [==============================] - 0s 33us/sample - loss: 0.4759 - acc: 0.7599\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.80      0.69      0.74       672\n",
      "         1.0       0.73      0.83      0.77       673\n",
      "\n",
      "    accuracy                           0.76      1345\n",
      "   macro avg       0.76      0.76      0.76      1345\n",
      "weighted avg       0.76      0.76      0.76      1345\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred3 = ANN(x_train,y_train,x_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "c256e01c",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_final = []\n",
    "\n",
    "for i,ele in enumerate(y_pred1):\n",
    "    sum = ele + y_pred2[i] + y_pred3[i]\n",
    "    if(sum>1):\n",
    "        y_pred_final.append(1)\n",
    "    else:\n",
    "        y_pred_final.append(0)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "4dff4bb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.80      0.82      0.81       672\n",
      "         1.0       0.81      0.79      0.80       673\n",
      "\n",
      "    accuracy                           0.81      1345\n",
      "   macro avg       0.81      0.81      0.81      1345\n",
      "weighted avg       0.81      0.81      0.81      1345\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test,y_pred_final))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
